# 大数据时代的伦理与道德

> 前言：在现今的社会，大数据的应用越来越彰显他的优势，它占领的领域也越来越大，电子商务、O2O、物流配送等，各种利用大数据进行发展的领域正在协助企业不断地发展新业务，创新运营模式。有了大数据这个概念，对于消费者行为的判断，产品销售量的预测，精确的营销范围以及存货的补给已经得到全面的改善与优化。但是，任何事物都是有两面性的，大数据在为我们的生活提供便捷的同时，其中潜在的伦理问题同样值得我们每个的思考！

## 何为大数据(from wikipedia)

大数据（英语：Big data），又称为巨量资料，指的是传统数据处理应用软件不足以处理它们的大或复杂的数据集的术语。大数据也可以定义为来自各种来源的大量非结构化或结构化数据。

![](http://ww1.sinaimg.cn/large/007jCw9lgy1fxkmhvzprvj30mk0cogmp.jpg)

## 存在的问题

#### 1. 数据采集的伦理问题：

> 以往的数据采集皆由人工进行,被采集人一般都会被告知,而如今的大数据时代,数据采集都被智能设备自动采集,而且被采集对象往往并不知情。例如我们每天上网所产生的各种浏览记录,在网上聊天时候的聊天记录,我们手机的通话和短信记录,我们在公共场合出入的监控记录,如此等等,都在我们不知情的情况下被记录和储存下来。

#### 2. 数据使用的隐私问题：

> 小数据时代,人们采集的数据基本上都是一数一用,采集时通过模糊和隐匿,可以防止在数据使用或再使用中隐私被泄露的问题。此外,数据与数据之间相对来说比较难建立起联系,因此难于发现隐藏在其中的秘密。但是,在大数据时代,各种数据都被永久性地保存着,这些数据汇集在一起形成大数据,这些大数据可以被反反复复永久使用。从单个数据来说,经过模糊化或匿名化,隐私信息可以被屏蔽,但将各种信息汇聚在一起而形成的大数据,可以将原来没有联系的小数据联系起来。大数据挖掘可以将各种信息片段进行交叉、重组、关联等操作,这样就可能将原来模糊和匿名的信息重新挖掘出来,所以对大数据技术来说,传统的模糊化、匿名化这两种保护隐私的方式基本上失效。

#### 3.数据取舍中的伦理问题：
  
> 在小数据时代,遗忘是常态。但是,由于网络技术和云技术的发展,信息一旦被上传网络,则立即被永久性地保存下来,就像白纸染上墨迹一样,我们很难彻底清除。于是,在大数据时代,记忆成了新常态,而遗忘则成了例外。例如,由于不小心而没有及时偿还银行信用卡的透支,这不良信用可能会被跟随一辈子,成为当事人的噩梦。有些人做过某种错事,大数据将此事永远存储下来,时不时又被人翻起而成为一个永远的伤疤。这种永久存储的技术让不少人失去了重新做人的机会,给当事人带来永远的灾难。因此,当事人是否有权要求删除自己的相关信息呢?在大数据时代,究竟由谁来决定数据的取舍? 


[大数据时代的伦理隐忧]<http://www.cssn.cn/bk/bkpd_qkyw/bkpd_bjtj/201506/t20150625_2048157_1.shtml>

## 事例

#### 1. 谷歌为假药打广告

    谷歌的广告部门为了利润，主动帮助卖假药者规避其公司的合规审查，使得大量假药、走私处方药、非法药物（如类固醇）广告网页长时间充斥其搜索结果。本案由FBI调查，于几年前和解，谷歌被罚款5亿美元。

以下是原文链接

[How a Career Con Man Led a Federal Sting That Cost Google $500 Million]
<https://www.wired.com/2013/05/google-pharma-whitaker-sting/>

调查的过程这里不多做赘述，概括来说，就是一个叫惠特克的卖假药的骗子被捕后，为了减刑，提供了谷歌公司收了自己大笔广告费给自己的假药打广告的情报。最终联邦情报局探员证实，谷歌的广告部门确实有专员指导假药商如何绕过算法的限制，将自己的商品被推到相关关键词的搜索界面上。最终，在2011年8月，谷歌与政府达成和解，谷歌公司被处罚五亿美元。 

![](http://ww1.sinaimg.cn/large/007jCw9lgy1fxknp9qbzaj30sg0htwgl.jpg)

然而此次事件过后，谷歌似乎仍未完全禁止非法药物投放的广告。据新浪科技报道，2013年6月，全美检察官协会（National Association of Attorneys General）联合主席吉姆•胡德（Jim Hood）向谷歌提出指控，称其仍允许贩卖非法、假冒药物的网上药店投放广告。

胡德表示：「我们每次对谷歌的搜索引擎进行检测，都不难找到非法商品，包话经营非处方危险药物及各类假冒商品的网站。这表示谷歌纵容非法行为，置消费者于危险境地，并且从中获利。」

想了解更多内容请看一下链接

[谷歌仍未禁止非法药物广告]<http://tech.sina.com.cn/i/2013-06-08/01228424417.shtml>

[Google 真的「不作恶」吗？]
<https://www.zhihu.com/question/19656857/answer/23181810>

#### 2. 美国“棱镜门”事件

　　2013年6月，美国中央情报局前雇员斯诺登向媒体曝光美国国家安全局和联邦调查局代号为“棱镜”的秘密项目，其直接接入苹果、微软、谷歌、雅虎等九大互联网公司的中心服务器，针对境外非美国人搜集情报，用户的电子邮件、在线聊天、信用卡信息等都无密可保。“棱镜门”的曝光暴露了全球社交网站甚至企业网站时刻都处在严密的监控中，导致企业及个人用户的信息安全受到威胁。

　　这一案例引发对信息伦理中个性化服务与隐私权之间矛盾的研究，用户期望得到企业的个性化服务，企业期望得到政府的特殊对待，无形中允许了政府以及企业获取隐私信息。人们当然希望企业、政府能一身正气将信息用在便捷工作生活上，但获取的程度却难以界定，由此引起了信息伦理问题的产生。

[美国棱镜门事件]<http://opinion.china.com.cn/event_2213_1.html>

## 各方观点
#### 1.下面是第一种观点，引用自《社会与科学》中邱仁宗、黄雯、翟晓梅等人的文章《大数据技术的伦理问题》。

[大数据技术的伦理问题]<https://wenku.baidu.com/view/0e41ffd8d1f34693dbef3e24.html>

　　与所有技术一样，大数据技术本身无所谓“好”与“坏”，因此它在伦理学上是中性的。然而使用大数据技术的个人、公司有着不同的目的和动机。技术被应用后，会因为使用对象的目的不同而对个人、公司乃至社会产生积极或消极的影响。然而值得注意的是，大数据技术具有一种强制性功能，会通过产生或处理海量、多样的数据，改进产品设计、研发、销售和管理行动（个体化的产品和服务），推动公司或机构进一步、更完全地进入个人的生活，并产生更深的影响，甚至改变像身份、隐私等术语的传统意义以及改变我们的社会、经济、政治和文化生活。而且，与所有新技术一样，大数据技术也将产生意料之外的风险。 

　　因此，在伦理学上我们要做的第一件事是鉴定大数据技术可能引发的风险。美国国家科学基金会支持学术界人士成立了“大数据、伦理学与社会理事会”，NSF的FenZhao女士指出，理事会的任务是促进宏观的对话来帮助更多的人了解大数据可能引起的风险，并在促使执行官和工程师思考改善产品和增加营业收入的同时，避免涉及隐私以及其他棘手问题的灾难，告诫不要重蹈美国Tuskegee梅毒研究的覆辙。 

　　那么，可鉴定出哪些风险？根据有限数据重新标识身份，可能泄露医疗记录、个人习惯、财务状况以及家庭关系这些私密信息，被人利用、假冒、诈骗；许多消费者毫不经意地使用社交媒体或互联网服务，无意中允许他人使用信息；根据数据分析掌握某些人犯罪活动模式，预先控制他们的犯罪行为，然而模式是根据过去行为确定的，不能完全决定未来的实际行为（这里也涉及决定论与自由意志、过去与未来关系等哲学问题）；基于先进的数据分析技术，零售商向顾客提供个体化服务，顾客接受这种服务后，零售商进一步提供有目标的商品服务，使人怀疑推动顾客行为的是顾客真正的需求，还是基于数据分析技术的商品和服务；还有大数据分析的结果可能导致基于年龄、性别、族群、健康状况社会背景等的歧视，等等。 
　　
#### 2.以下是第二种观点，介绍了大数据时代存在的数据暴露在“第三只眼”下的问题。引用自《大众日报》中黄欣荣的文章《大数据时代的伦理隐忧》。

[大数据时代的伦理隐忧]<http://www.cssn.cn/bk/bkpd_qkyw/bkpd_bjtj/201506/t20150625_2048157.shtml>

　　现代智能技术为数据的采集提供了方便的技术手段,并形成了从天上到地下的一个全方位的监控,构成了一个立体的天罗地网。前东德曾雇佣了数十万的秘密警察来监控其国民的言行,花费了巨大的人力物力。如今利用现代智能技术,可以在无人的状态下每天24小时全自动、全覆盖地全程监控,毫无遗漏地监视着人们的一举一动。在大数据时代,我们的一切都被智能设备时时刻刻盯梢着,跟踪着,让人真正感受到被天罗地网所包围,一切思想和行为都暴露在“第三只眼”的眼皮底下。令人震惊的美国“棱镜门”事件是最典型的“第三只眼”的代表。美国政府利用其先进的信息技术对诸多国家的首脑、政府、官员和个人都进行了监控,收集了包罗万象的海量数据,并从这海量数据中挖掘出其所需要的各种信息。 

　　除了这种早已设计好的数据收集之外,更多的是无意中留下的各种数据。只要使用了网络或智能设备,我们的一举一动都已经被留下,并可能永久存储于云端。例如我们几乎每天都在使用Google、百度等搜索工具,只要进行过搜索,我们的搜索痕迹就被Google、百度永久地保存。我们现在都喜欢网上购物,在亚马逊、当当购书,在淘宝、天猫、京东商城购物,只要进入过这些网站,哪怕只随便点击了其中的某种物品信息,我们的兴趣、偏好、需求等等就被记录下来,并时不时收到各种推荐广告。我们在QQ、微信、Facebook等网络社交工具聊天,我们以为及时删除了聊天记录就万事大吉,其实网络早已偷窥了我们的秘密,并永久记录了下来。现在几乎人人都手机不离手,通话、短信、导航、搜索……功能数不胜数,我们以为只要注意及时删除,就只能天知地知,殊不知我们的一切早已记录在案。博客、微博、云空间等,也永久记录着我们的所思所想。我们的一切都以数据化的形式被永久记录下来,这些数据有些是被人强行记录的,有些是我们自己主动留下的。

#### 3.以下是第三种观点，引自自岳瑨在《马克思主义与现实》中发表的文章《大数据技术的道德意义与伦理挑战》。

[岳瑨:大数据技术的道德意义与伦理挑战]<http://phil.cssn.cn/zhx/zx_llx/201707/t20170714_3579934.shtml>

　　大数据技术是物的数据化与数据的物化的统一。物的数据化是指让数据发声以说明世界，数据的物化是指通过挖掘相关关系以改变世界。两方面相互依存、不可分割，体现了大数据技术在描述和预测中带来价值图式、文明指引和道德前景的变化。与大数据技术内含的道德意义相关，它面临的伦理问题可归结为如下五个方面。

(一)在增进整体人类福利时如何缩小数字鸿沟?

　　“数字鸿沟(Digital Divide)”指不同群体对于信息技术使用的巨大差异。基于对“使用差异”的不同理解，数字鸿沟有四种：可及——不同群体或个人在获取技术以及在信息可及方面存在的技术鸿沟；应用——不同群体或个人在通过互联网获取资源方面存在的应用鸿沟；知识——不同群体或个人在通过互联网获取知识方面存在的知识鸿沟；价值——使用者因自身价值观方面的原因导致的在运用大数据方面存在的深层次数字鸿沟。在大数据时代，随着移动互联网和云计算的普及，“鸿沟”及由此导致的公平正义问题不再主要地集中于技术接人或信息接入方面，可及、应用和知识方面的鸿沟正在缩小，而价值鸿沟则变得日益凸显。由于数字鸿沟的概念涉及在信息技术以及有关的服务、通讯和信息可及等方面的失衡关系，它会在全球、各国或各地区贫富之间、男女之间、受教育与未受教育的人群之间导致信息可及、资源应用、知识获取和价值区隔等方面的不平等和不公平。“鸿沟”只能逐步缩小，但仍将长期存在。而如何缩小“价值鸿沟”会变得越来越突出，也越来越重要。这是大数据技术面临的一个世界性和人类性的价值伦理学难题。

(二)在促进公共善时如何防范数据失信和数据失真?

　　由于大数据使量化世界成为可能，自然、社会、人类的一切状态和行为都可转化为数据而被记录、存储和传播，因而形成了与实体化的物理足迹相对应的“幽灵化”的数据足迹。它带来的潜在伦理风险是“无法摆脱的过去”对人之生存的压迫。如果人们担心“数据足迹”对个人职业生涯和未来生活造成不利影响，就有可能采取隐瞒、不提供或提供虚假数据来“玩弄数据系统”。如果一个社会的信任资源状况不佳，玩弄数据系统的行为就会变得非常普遍。大数据面临精准性、可信度、无污染三大挑战。这使得大数据技术在公共善的层面上面临信任悖论，即预设为可信的数据资源变得不可信。因此，治理或防范数据失信和失真，包括治理数据污染或“清洗”脏的数据、不可信的数据和虚假数据等，将是大数据技术面临的公共伦理学难题。

(三)在展现开放共享的伦理时如何保护个人隐私和安全?

　　在文化、教育、经济、政治、医疗、社会等诸领域运用大数据，必须在互信和共享的环境中进行。大数据技术在这一维度带来了个人隐私的泄露和保护的伦理问题。学校利用数据平台收集和分析某个学生的敏感信息是否侵犯个人隐私?政府机构或企业对个人信息进行收集、监控和分析处理是否符合隐私规则?医疗数据、商业数据、科研数据甚至个人日常生活中产生的数据等等，面临同样的问题。英国学者帕克用“全民监控”一词来描绘大数据时代的安全与隐私困境。国际上第一本《大数据伦理学》将隐私规则面临的挑战看作是大数据伦理学的核心问题。我国学者邱仁宗、吕耀怀、段伟文等人的研究也表明，大数据技术带来了对个人隐私保护及对个别组织滥用或垄断数据的担忧。对庞大的数据进行实时和准实时的分析对一种新型职业即“算法专家”的职业道德提出了很高的要求。“算法专家”既可以促进公众对大数据会得到正确且适当应用的信任也可以导致公众的不信任，既可以剔除害群之马也可以成为害群之马。在大数据时代，政府、公司、算法专家是时代的“牧首”，他们既可观察“羊群”，也可观察其中“某一只羊”。个人隐私在大数据的“聚光灯”下会无所遁形。大数据时代是否需要重构与之相应的保护个人隐私和安全的伦理?这是大数据技术面临的日益敏感的隐私伦理学难题。

## 反思与应对

#### 1.提高数据使用中的价值透明度
  
>尽管对于技术是中立的还是负载价值的是学者们持续讨论的议题，技术乐观主义者和悲观主义者都有各自的观点，但笔者认为技术是负载价值的。在使用大数据技术的过程中，无论是工程设计过程还是产品的使用过程都暗含着价值，但是使用者往往不知情。消费者在进行购物行为的时候往往不会注意到其个人信息已经被搜集和利用，这就需要组织在使用不同数据过程中提高其负载价值的透明度。承认和尊重人们对未知的恐惧，明确告知用户哪些数据被搜集和使用，可能被使用的范围，数据用途的价值倾向，以及需要承担的风险，这符合与道德决策相关的自主原则、知情同意原则。康德及其他哲学家强调，人之为人的要素之一便是自决的能力。[7]52将选择权回归个人，有助于在大数据的应用中减少风险推论的冒险性。为了增加可行性和控制成本，使用涉及个人数据的具体操作中，可以以公告或邮件的形式通知个人，同时保留个人拒绝的权力至少是要求匿名的权力，并保证在使用数据时语境的完整性。
  
#### 2.调整个人的隐私观
  
> 大数据时代，既然个人的隐私观是产生隐私问题的重要原因之一，那么促进社会中的主体增强隐私意识，调整隐私观念是解决问题的必由之路。增强隐私意识有助于形成适合自身的隐私观，达到隐私行为与观念的统一，减少矛盾的形成。增强隐私意识还有助于在使用大数据相关产品的同时注重隐私保护。例如有选择的使用软件；在分享文字、照片的时候尽量避免敏感的个人信息；当公司行为侵犯到个人隐私的时候具有维权意识。当然目前个人的选择权还是相对弱势的，这需要个人在大数据时代调整自己的隐私观，使观念与时代相适应，并不断寻求更能保护自身隐私的行为方式。
  
#### 3.搭建共同价值平台
  
> 组织与个人具有共同的价值，有助于减少在行动中涉及隐私问题时因利益多样性而产生的矛盾。在大数据产品设计和服务过程中，将个人价值与组织价值相结合，使各方在隐私问题上达成初步共识。这要求各方在行动时聚焦如何解决问题，而不是将时间浪费在通过道德界定解决哪些问题。一方面提高组织与组织中成员的价值一致性，有助于降低成员与组织之间在隐私问题上的矛盾，提高工作效率；另一方面提高组织中管理者、工程师与用户价值的一致性，在产品设计时考虑到用户的可接受程度，生产出符合共同价值的产品，以减少涉及隐私问题时产生的矛盾。
  
#### 4.寻求合理的伦理决策点
  
> 在大数据产品设计的过程中，伦理决策点尤为重要，它将影响到对数据使用的深入程度。组织和个人通过调查与协商寻找利益平衡的伦理决策点，达到观念的一致，将成为缓解这种问题的可行之路。由于作为决策主体的组织和个人往往都从自身的利益出发，很难客观地进行决策，可以引入第三方机构客观调研，共同寻找伦理决策点。第一，进行深入道德调查，通过问卷及用户同意书等方式展开伦理对话，得知其他人是怎么认为的。第二，分析调查结果，进行处理和评估，明确要设计的产品是否与已确定的价值观相符，用户可接受的范围。第三，结合双方的需求达到价值可接受。最后，告知决策结果，如何分享和使用这些数据。第三方机构进一步发展，将可能成为个人数据代理机构，即个人授权第三方机构帮助管理其个人数据。目前还没有成熟的具备这种能力的机构，往往是组织自身在充当这个角色，发展成熟的第三方机构是客观要求。

[大数据隐私伦理问题探究]<http://www.cssn.cn/zhx/201507/t20150721_2086858_4.shtml>

## 小结

引用大众日报[大数据时代的伦理隐忧]<paper.dzwww.com/dzrb/content/20150624/Articel10002MT.htm>文中的一段: 
大数据技术是信息技术的延续,信息社会刚刚提出并兴起之时,人们也曾担心害怕,一如当下的大数据革命。**任何技术都是一把双刃剑,这把剑是利是害,完全取决于持剑之人。大数据技术只是放大了人类原本就存在的或明或暗的人类本性,所以对大数据的规制其实还是对我们人本身的规制。**

#### 　再次申明：本文的看法均为引用，已注明来源，不代表本人的观点。

